---
title: 超越流式遍历
sidebar_position: 1
toc_min_heading_level: 2
toc_max_heading_level: 5
slug: /projectDesign/beyondStream
---

### 流式系统的硬伤

[//]: # (<img src="/Users/liufei/docs/typora笔记/images/analysis-project/ana-6.png" alt="image" style="zoom:32%;" />)
<div style={{ textAlign: 'center', width: '100%' }}>
    <img src="/analysis-project/img/analysis-project/ana-6.png" alt="image" style={{ maxWidth: '90%', height: 'auto', display: 'block', margin: '0 auto' }} />
</div>

上一个文章中的流式系统设计，虽然被实战证明过能运行良好，但其存在设计上的硬伤，让它并不能成为一个优秀的分析系统。因为本质上其就是用流式遍历的方式来处理数据，所有任务都是转化为对数据的遍历处理，无论是实时的数据还是历史的数据，都是转化为数据流去一条条过滤。其至少在如下方面存在硬伤：

- **数据的输入粒度会影响分析和质检效果**，比如：分析会话数据，那输入的数据粒度就是会话中的消息，因为会话是个更大粒度的事件，实时监控就需要分析每条会话而不是等会话结束按会话为维度。但因为后续的分析流程是一个个以消息为维度的算子序列，当要处理更大维度的场景时，就会捉襟见肘，要么用新的算子再分析一遍用要么就只能在消息算子中处理会话消息这必然不如分析完整会话更加准确。

- **流式遍历实际上效率很差，任务增加总是需要更多的资源**，可以从图中看到，每个消息都会去过每个任务，消息数量和任务数量的乘积就是整个系统的工作量，也就是当消息数据很多时，随便增加一两个任务就可能让整个系统无法处理完消息。增加线程thread或者cpu核心而增加的处理能力和任务增加带来的任务增量是同一个量级的，现实中不可能资源的增加赶得上任务的增加的。所以当数据量到了处理能力的瓶颈时，解决起来就很不经济。

[//]: # (<img src="/Users/liufei/docs/typora笔记/images/analysis-project/ana-7.png" alt="image" style="zoom:50%;" />)
<div style={{ textAlign: 'center', width: '90%' }}>
    <img src="/analysis-project/img/analysis-project/ana-7.png" alt="image" style={{ maxWidth: '50%', height: 'auto', display: 'block', margin: '0 auto' }} />
</div>

- **当消息进入分析序列之后，结果的判断存在歧义**，因为算子是返回`boolean`结果，当一个消息只要进入了分析序列，就必然是`true`和`false`的结果组合，但事实上消息还存在第三个结果就是`unrelated`不相关，这时就会发现无论怎么判定`true`和`false`，都是不准确的。可以通过分析项的组合和算子的配置来优化，但这也是无法解决问题的，因为不可能把所有数据情况都考虑到，只要不能保证进入的数据都是合适的数据，这个问题就始终存在。
- **按任务来组织分析项并编排执行的算子序列，并不是高效的执行序列**，因为不同算子之间执行的内容是不一样的，所以如果在算子序列执行中，遇到了某个算子性能很慢或者阻塞，会导致整个任务的执行序列都很慢，执行任务线程池也是以一个个算子序列来执行，很难去优化它因为算子之间都是串行在一起。这就是明明CPU的整体使用率都不高，但系统就是处理不完任务。



### 更好的设计模型

一个更好的分析或者质检系统，在设计上肯定是超越流式遍历的，如果使用流式遍历来处理数据，上面提到的硬伤无论如何都是无法避免的(--*如果能避免我还在研发那个系统时早就将它改掉了*)。

**更好的设计模型核心就是将遍历变成搜索，只是要完全达到上面流式遍历能完成的所有任务逻辑，需要对数据进行更复杂的处理，并建立合适而准确的数据关系模型。**

[//]: # (<img src="/Users/liufei/docs/typora笔记/images/analysis-project/ana-9.png" alt="image" style="zoom:50%;" />)
<div style={{ textAlign: 'center', width: '100%' }}>
    <img src="/analysis-project/img/analysis-project/ana-9.png" alt="image" style={{ maxWidth: '90%', height: 'auto', display: 'block', margin: '0 auto' }} />
</div>

#### 效率对比

首先当把大数据按照规则的进行遍历时，其实就是在先过滤无效数据，然后执行触发逻辑。因为绝大多数据都是无效的，到最后绝大多数数据都丢掉了。如果大部分数据最后都要被处理并做存储，那这样的遍历做法才是对的，但问题就是只要极少数的数据，但却总是在去遍历范围内的所有数据，而大量的任务需要编排、大量逻辑被触发、api和查询被调用、并且数据还需要协调并发，这就导致系统资源大多时候是在做实际上的无用功。

而要转化为搜索模型，则需要将数据接入时的处理和后面任务的执行分开，就和`Lucene`搜索引擎的数据分析阶段和搜索阶段是一模一样的，只是这里的搜索还不仅仅包括`Lucene`，因为`Lucene`无法识别业务模型，所以还需要引入`Neo4j`这类能表示丰富关系的搜索组件。

> *其实上面的直观系统也在使用`ElasticSearch`，但使用的深度不够，并且其也无法识别业务模型，导致不能完成任务而被迫采用一种直观而简单的处理模型*

变成搜索模型之后，在数学上可以证明：

> 如果一个规则`function()`和一个数据`data`的执行，那必然是`sum(functionA,functionB...) * sum(dataA,dataB...) `的关系。而将转化成搜索模型之后，数量关系将变成`sum(functionA,functionB...) * O(sum(dataA,dataB...))`的关系，这里的大O就是搜索的复杂度，良好的数据模型能够将要执行的数量减少至少一个数量级即`sum(functionA,functionB...) * log(count(dataA,dataB...))`。本质上就是将全量数据遍历变成按索引检索，而规则就是查询条件而已。

两者效率曲线的对比就如下图：

[//]: # (<img src="/Users/liufei/docs/typora笔记/images/analysis-project/ana-0.png" alt="imag" style="zoom:42%;" />)
<div style={{ textAlign: 'center', width: '100%' }}>
    <img src="/analysis-project/img/analysis-project/ana-0.png" alt="image" style={{ maxWidth: '56%', height: 'auto', display: 'block', margin: '0 auto' }} />
</div>

[desmos函数软件](https://www.desmos.com/calculator)

从这个效率曲线可以看到，在任务数量比较小的阶段，流式遍历的曲线是要比搜索模型曲线要好的，原因在于：搜索模型在小规模或者任务前期会比流式遍历有更多的任务负担，因为其需要去分析输入的内容，并建立索引，以及对相应关系结构的构建(比如：neo4j构建关系)。这也就是函数曲线中的前段。

但当随着需要处理的任务的增加，因为每次任务处理实际上都是对数据的搜索(此搜索包含Lucene、Neo4j等复合搜索)，这些搜索都是很快的。所以随着任务的增加流式遍历会呈现数据量和任务数量呈现 `m*n` 乘积关系而使得任务对cpu和io的负担快速增加(io增加是因为本身任务处理需要数据检索)。而搜索模型则是数据量和任务数量呈现`logm * n`的关系，这也就是上图后半段的资源消耗曲线比流式遍历至少小一个数量级的原因。



#### 数据输入粒度兼容

因为流式遍历要一条条的过滤数据，所以其中处理粒度就会影响结果，无论怎么拆分粒度都有无法兼顾的地方。但转化为搜索模型之后，因为最终的处理结果即搜索结果和数据解析过程是分开的，数据解析和分析过程可以兼容任何粒度，比如会话可以、消息可以、文本可以、甚至不同类型的内容如图片、视频也可以。

最终的效果取决于数据解析和分析阶段建立的索引和关系，不同任务就取决于具体的搜索语句。



#### 结果歧义的解决

结果的判断存在歧义其实也是因为数据的不相关性导致的，因为遍历数据，而任务又是自定义的，这就不可避免的导致有和任务算子执行逻辑不相符不相关的数据，这才导致无论怎么判定true/false都不恰当的问题。

而搜索模型是基于搜索、然后再是关系模式匹配比如neo4j、最后才是结果的运算合并。这天然就不存储无关数据影响判断结果的问题，如果有那也很好优化数据搜索，而编排固定的串行算子序列，不可能根据每个算子去再过滤数据它只负责判断true/false，所以它解决不了歧义的问题，但搜索却是很好处理此问题。



#### 执行性能的优化

上面流式系统中，整体性能无法有效释放的原因在于，其任务的组织是由用户根据业务逻辑自定义的，然后编排出来的算子执行序列是动态的，很难根据各个算子的执行情况去优化其执行拓扑结构并使用更好的编程模型。

搜索模型则可以，因为搜索模型中最终的任务执行的业务逻辑都是搜索（只是搜索的内容更多：`Lucene`、`Neo4j`、`redis`、`MySql`等），这样我业务逻辑随便怎么自定义编排出来的执行序列都是很快的只涉及搜索而已。繁重的部分在前期解析数据和分析数据并建立关系和索引的阶段，而这个阶段是不受自定义任务影响的，可以按任务的类型将任务调整成更高效的拓扑结构，具体的内容并发模型就可以使用`Disruptor`框架。



#### 搜索模型仍然需要流式系统

虽然搜索模型是更加优秀的设计，但仍然需要流式系统。因为搜索模型很难处理实时触发、比如触发关键词、触发关键对象或模块立刻执行后续逻辑；然后遇到时间窗口的数据实时统计，搜索模型也很难处理。而这两个问题是流式系统很容易处理的，所以在使用搜索模型之后仍然需要流式系统，但流式系统可不会像上图中直观系统那样处理的那么复杂；可以直接使用`Kafka Stream`来集成到`Kafka`中，因为现在的消息中间件大多使用`kafka`，所以可以无缝集成`Kafka Stream`来弥补搜索模型的不足。



#### 还需要解决的问题

变成搜索模型之后，之前可能很简单的实现将会变得不一样，可能会更加复杂。但不管怎么样，还有如下问题是需要新的搜索模型去解决的：

- 随时安全停机更新，如果整个流程是揉在一起的，没 有一个可以安全停机的节点，特别如果当所有的功能都集中在一个应用中时那就是更不存在数据处理过程中的安全停机节点了，所以要么能很好的拆分应用使得需要频繁部署快速迭代的应用不影响在运行中的数据，要么就是有一个安全点能停机然后继续。

- 本身因为对业务逻辑关系而存在对外部依赖的处理，处理的不好，很耗时，而且对外部的性能和能承受的tps很敏感。

- olap数据处理要不够优秀 --比如`es`的聚合其实不是精确值。
- 。。。



后面的文章就会讲其中的解决办法和细节

